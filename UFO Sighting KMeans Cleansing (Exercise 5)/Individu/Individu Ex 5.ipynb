{"cells":[{"cell_type":"code","source":["path = sqlContext.sql(\"select url from nasa where date is not null\").rdd.map(tuple)"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["path_arr = path.collect()"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["path_arr[:10]"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["base = []\nfor x in path_arr:\n  if 'GET' in x[0]:\n    temp = x[0].split(' ')[1]\n    if temp != '' and '/' in temp:\n      base.append(x[0].split(' ')[1].split('/')[1])"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["baseCount = {}\nfor row in base:\n  if row in baseCount:\n    baseCount[row] += 1\n  else:\n    baseCount[row] = 1"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["from operator import itemgetter\nfilter = {}\nfor i in baseCount:\n  if baseCount[i] > 20:\n    filter[i] = baseCount[i]"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["filter"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["from operator import itemgetter\nfrom pyspark.sql import Row\nlist = []\nfor key in filter:\n  list.append([key, filter[key]])\nlist = sorted(list, key=itemgetter(1))\nlist = map(lambda x: Row(Base=x[0],Count=x[1]), list)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["dataFrame = sqlContext.createDataFrame(sc.parallelize(list))\ndataFrame.registerTempTable(\"chosen\")"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["display(sqlContext.sql(\"select * from chosen\"))"],"metadata":{},"outputs":[],"execution_count":10}],"metadata":{"name":"Individu Ex 5","notebookId":15573972697372},"nbformat":4,"nbformat_minor":0}
