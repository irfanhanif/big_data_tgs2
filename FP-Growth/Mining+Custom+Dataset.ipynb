{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark_path = \"D:/spark\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ['SPARK_HOME'] = spark_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ['HADOOP_HOME'] = spark_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ['PYSPARK_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.append(spark_path + \"/bin\")\n",
    "sys.path.append(spark_path + \"/python\")\n",
    "sys.path.append(spark_path + \"/python/pyspark/\")\n",
    "sys.path.append(spark_path + \"/python/lib\")\n",
    "sys.path.append(spark_path + \"/python/lib/pyspark.zip\")\n",
    "sys.path.append(spark_path + \"/python/lib/py4j-0.10.4-src.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.conf.SparkConf at 0x6769ef0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = SparkConf()\n",
    "conf.set(\"spark.executor.memory\", \"2g\")\n",
    "conf.set(\"spark.cores.max\", \"4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = SparkContext(\"local\", conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.context.SparkContext object at 0x0000000006769D68>\n"
     ]
    }
   ],
   "source": [
    "print sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataPath = \"csv-dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = sc.textFile(dataPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'\"Nasi, Sosis, Telur Dadar\"',\n",
       " u'\"Nasi, Sayur Lodeh, Tempe\"',\n",
       " u'\"Nasi, Urap-urap, Ayam Goreng\"',\n",
       " u'\"Nasi, Sayur Bayam, Dadar Jagung\"',\n",
       " u'\"Nasi, Udang Goreng, Ayam Goreng\"',\n",
       " u'\"Nasi, Ayam Bakar, Sambal\"',\n",
       " u'\"Nasi, Semur, Bawang Goreng\"',\n",
       " u'\"Nasi, Ayam Bakar, Tahu, Tempe\"',\n",
       " u'\"Nasi, Cumi-cumi, Ayam Goreng\"',\n",
       " u'\"Nasi Pecel, Ayam Suwir, Peyek\"']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datasetParsed = dataset.map(lambda x: x.replace('\"', \"\").replace(\" \", \"\").replace(\"Nasi,\", \"\").split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'Sosis', u'TelurDadar'],\n",
       " [u'SayurLodeh', u'Tempe'],\n",
       " [u'Urap-urap', u'AyamGoreng'],\n",
       " [u'SayurBayam', u'DadarJagung'],\n",
       " [u'UdangGoreng', u'AyamGoreng'],\n",
       " [u'AyamBakar', u'Sambal'],\n",
       " [u'Semur', u'BawangGoreng'],\n",
       " [u'AyamBakar', u'Tahu', u'Tempe'],\n",
       " [u'Cumi-cumi', u'AyamGoreng'],\n",
       " [u'NasiPecel', u'AyamSuwir', u'Peyek']]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetParsed.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.fpm import FPGrowth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = FPGrowth.train(datasetParsed, 0.04, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FreqItemset(items=[u'AyamBakar'], freq=6),\n",
       " FreqItemset(items=[u'Tahu'], freq=9),\n",
       " FreqItemset(items=[u'Perkedel'], freq=4),\n",
       " FreqItemset(items=[u'TelurDadar'], freq=8),\n",
       " FreqItemset(items=[u'SayurBayam'], freq=4),\n",
       " FreqItemset(items=[u'Sosis'], freq=5),\n",
       " FreqItemset(items=[u'UdangGoreng'], freq=4),\n",
       " FreqItemset(items=[u'SayurAsem'], freq=4),\n",
       " FreqItemset(items=[u'BawangGoreng'], freq=6),\n",
       " FreqItemset(items=[u'AyamGoreng'], freq=12),\n",
       " FreqItemset(items=[u'Rawon'], freq=4),\n",
       " FreqItemset(items=[u'SayurLodeh'], freq=4),\n",
       " FreqItemset(items=[u'Lalapan'], freq=7),\n",
       " FreqItemset(items=[u'Peyek'], freq=4),\n",
       " FreqItemset(items=[u'MieGoreng'], freq=6),\n",
       " FreqItemset(items=[u'MieGoreng', u'TelurMataSapi'], freq=5),\n",
       " FreqItemset(items=[u'TelurMataSapi'], freq=9),\n",
       " FreqItemset(items=[u'Sambal'], freq=5),\n",
       " FreqItemset(items=[u'Sambal', u'Lalapan'], freq=4),\n",
       " FreqItemset(items=[u'Tempe'], freq=9),\n",
       " FreqItemset(items=[u'NasiPecel'], freq=4),\n",
       " FreqItemset(items=[u'NasiPecel', u'Peyek'], freq=4)]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.freqItemsets().collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
